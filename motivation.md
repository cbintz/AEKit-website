---
layout: page
title: Motivation
---

**Questions**

The project seeks to answer questions around algorithmic ethical issues and concerns by designing an Algorithmic Equity Toolkit. The toolkit aims to help civil rights advocates identify and audit algorithmic processes and systems of surveillance tools and Automated Decision Systems  in the public sector.

Questions we ask are: what ethical issues should civil rights advocates be concerned with in regards to surveillance and automated decision systems? How are algorithmic systems reinforcing bias and discrimination? What do community members and non-tech experts understand about algorithmic tools and their impacts? What should they know about surveillance and automated decision systems to identify them and know how they work?

The toolkit includes three components 1) a surveillance and automated decision system identification guide that helps civil rights advocates identify them and understand how they work, 2) a questionnaire of red flags for surfacing the social context of a given system, its technical failure modes (i.e., potential for not working correctly, such as false positives), and its social failure modes (i.e. its potential for discrimination when working correctly); and (3) an interactive web demo that illustrates the underlying mechanics, inaccuracies, and potential harms of facial recognition technology.

The project fills a critical gap in non-expert understanding of complex and proprietary algorithmic systems and seeks to help community members ask pointed questions about algorithmic technologies, for their own understanding and to elected officials.


**Background**

Why is this important?
What work has previously been done?

**Stakeholders**
Stakeholder engagement is a principal component to the development of our toolkit. The ACLU and the Community Centered Tech Coalition are the two stakeholders central to our project. We are engaging with them through face-to-face meetings to gain insight into their mission and work with tech fairness policy. In our meetings, we try to build a better sense of the methods in which they do their work to guide our design process of the prototypes for our toolkit elements. We are taking into consideration the concerns they express for the impact that algorithmic bias has on their community of interest and striving to strike a balance between addressing their specific needs and keeping the toolkit applicable to the general community.

We envision our stakeholders using our toolkit to better inform their activism efforts in regards to tech fairness policy. We foresee community members and organization leaders using the toolkit to aid their understanding of algorithmic bias and the use of algorithmic systems in both society at large and specifically in the City of Seattle.

**Ethics**

What are the ethical questions you considered as a team?
How are you addressing them in your work?
